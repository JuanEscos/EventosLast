name: 02EventosPastINFO

on:
  schedule:
    - cron: '1 4 * * *'  # Ejecutar diariamente a las 04:01 UTC
  workflow_dispatch:  # Permitir ejecución manual

jobs:
  scrape-and-process:
    runs-on: ubuntu-22.04
    env:
      TZ: Europe/Madrid
      HEADLESS: "true"
      MAX_SCROLLS: "15"
      SCROLL_WAIT_S: "3.0"
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        cache-dependency-path: requirements.txt

    - name: Install Chrome and ChromeDriver
      run: |
        sudo apt-get update
        sudo apt-get install -y wget gnupg
        
        # Instalar Chrome
        wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
        echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable
        
        # Instalar ChromeDriver compatible
        CHROME_VERSION=$(google-chrome-stable --version | grep -oE '[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+')
        echo "Chrome version: $CHROME_VERSION"
        
        # Descargar ChromeDriver específico para la versión
        CHROME_MAJOR_VERSION=$(echo $CHROME_VERSION | cut -d'.' -f1)
        CHROMEDRIVER_URL="https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/${CHROME_VERSION}/linux64/chromedriver-linux64.zip"
        
        # Intentar descargar la versión específica
        if wget -q --spider "$CHROMEDRIVER_URL"; then
            echo "Descargando ChromeDriver $CHROME_VERSION"
            wget -O chromedriver.zip "$CHROMEDRIVER_URL"
            unzip -o chromedriver.zip
            sudo mv chromedriver-linux64/chromedriver /usr/local/bin/chromedriver
            sudo chmod +x /usr/local/bin/chromedriver
        else
            echo "Usando ChromeDriver de apt como fallback"
            sudo apt-get install -y chromium-chromedriver
            sudo ln -sf /usr/bin/chromedriver /usr/local/bin/chromedriver
        fi
        
        # Verificar instalaciones
        which google-chrome-stable
        which chromedriver
        google-chrome-stable --version
        chromedriver --version

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install selenium beautifulsoup4 python-dotenv lxml requests

    - name: Create output directory
      run: mkdir -p ./output

    - name: Run Python scraper
      timeout-minutes: 90
      env:
         TZ: Europe/Madrid
         HEADLESS: "true"
         MAX_SCROLLS: "12"         # baja un poco
         SCROLL_WAIT_S: "2.0"
         LIMIT_EVENTS: "35"        # procesa solo 35 eventos por run
         MAX_RUNTIME_MIN: "25"     # parachute: cortar de forma ordenada a los 25'
      run: |
        echo "=== EJECUTANDO SCRAPER ==="
        python ./02eventsPastINFO.py --module all
        echo "=== SCRAPER COMPLETADO ==="

    - name: Verify generated files
      run: |
        echo '=== VERIFICANDO ARCHIVOS GENERADOS ==='
        ls -la ./output/
        
        # Verificar que existen los archivos finales
        missing_files=0
        required_files=("01events_past.json" "02events_pastINFO.json")
        
        for file in "${required_files[@]}"; do
            if [ -f "./output/$file" ]; then
                file_size=$(stat -c%s "./output/$file")
                echo "✅ $file: ENCONTRADO (${file_size} bytes)"
            else
                echo "❌ $file: NO ENCONTRADO"
                missing_files=$((missing_files + 1))
            fi
        done
        
        if [ $missing_files -eq 0 ]; then
            echo "✅ TODOS los archivos requeridos están presentes"
        else
            echo "❌ Faltan $missing_files archivos requeridos"
            exit 1
        fi

    - name: Compress JSON files for FTP
      run: |
        echo "=== COMPRIMIENDO ARCHIVOS PARA FTP ==="
        
        # Comprimir archivos JSON con gzip (máxima compresión)
        for file in ./output/0*.json; do
            if [ -f "$file" ]; then
                echo "Comprimiendo: $(basename $file)"
                gzip -9 -c "$file" > "${file}.gz"
                original_size=$(stat -c%s "$file")
                compressed_size=$(stat -c%s "${file}.gz")
                compression_ratio=$(( (compressed_size * 100) / original_size ))
                echo "  ${original_size} bytes → ${compressed_size} bytes (${compression_ratio}%)"
            fi
        done
        
        echo "=== ARCHIVOS COMPRIMIDOS ==="
        ls -la ./output/*.gz

- name: Upload compressed files to FTP
  env:
    FTP_SERVER: ${{ secrets.FTP_SERVER }}      # ej: ftp.midominio.com (sin protocolo, sin / final)
    FTP_USERNAME: ${{ secrets.FTP_USERNAME }}
    FTP_PASSWORD: ${{ secrets.FTP_PASSWORD }}
    FTP_REMOTE_DIR: ${{ secrets.FTP_REMOTE_DIR }}  # ej: /Competiciones (con / inicial, sin / final)
  shell: bash
  run: |
    set -euo pipefail

    echo '=== SUBIENDO ARCHIVOS COMPRIMIDOS ==='

    # Comprobar credenciales
    for v in FTP_SERVER FTP_USERNAME FTP_PASSWORD; do
      if [ -z "${!v:-}" ]; then echo "❌ ERROR: \$${v} vacío"; exit 1; fi
    done

    # Normalizar host: quitar protocolo y barras finales, y eliminar saltos de línea/espacios
    host="$(printf '%s' "${FTP_SERVER}" | tr -d '\r' | sed -e 's~^ftp[s]*://~~' -e 's~/*$~~' -e 's/[[:space:]]//g')"
    if [ -z "$host" ]; then echo "❌ ERROR: host vacío tras normalizar"; exit 1; fi

    # Normalizar directorio base: asegurar / inicial, sin / final, sin CR/LF
    base_dir="$(printf '%s' "${FTP_REMOTE_DIR:-}" | tr -d '\r' | sed -e 's~\r~~g' -e 's~//*~/~g')"
    base_dir="/${base_dir#/}"
    base_dir="${base_dir%/}"

    # Directorio final en el servidor
    remote_dir="${base_dir}/Competiciones/EventosPast/data"

    # Archivos a subir
    files=(
      "01events_past.json.gz"
      "02events_pastINFO.json.gz"
    )

    # Subir cada archivo
    for f in "${files[@]}"; do
      local_file="./output/$f"
      if [ ! -f "$local_file" ]; then
        echo "❌ No existe: $local_file"
        continue
      fi

      # URL final SIEMPRE en una sola línea y entre comillas
      url="ftp://${host}${remote_dir}/$f"

      echo "📤 Subiendo: $url"
      curl --fail \
           --ssl-reqd \
           --ftp-create-dirs \
           --disable-epsv \
           --user "${FTP_USERNAME}:${FTP_PASSWORD}" \
           --upload-file "$local_file" \
           "$url" \
        && echo "✅ $f subido" \
        || {
          echo "❌ Error subiendo $f. Intento con el original sin comprimir…"
          orig="${f%.gz}"
          [ -f "./output/$orig" ] || { echo "⚠️  No existe ./output/$orig"; continue; }
          url_orig="ftp://${host}${remote_dir}/$orig"
          curl --fail \
               --ssl-reqd \
               --ftp-create-dirs \
               --disable-epsv \
               --user "${FTP_USERNAME}:${FTP_PASSWORD}" \
               --upload-file "./output/$orig" \
               "$url_orig" \
            && echo "✅ $orig subido" \
            || echo "❌ También falló subir $orig"
        }

      sleep 1
    done

    # Subir además el 01events_past.json sin comprimir (opcional)
    if [ -f "./output/01events_past.json" ]; then
      url_plain="ftp://${host}${remote_dir}/01events_past.json"
      echo "📤 Subiendo sin comprimir: $url_plain"
      curl --fail \
           --ssl-reqd \
           --ftp-create-dirs \
           --disable-epsv \
           --user "${FTP_USERNAME}:${FTP_PASSWORD}" \
           --upload-file "./output/01events_past.json" \
           "$url_plain" \
        && echo "✅ 01events_past.json subido" \
        || echo "⚠️  No se pudo subir 01events_past.json sin comprimir"
    fi

    - name: Create backup directory
      run: mkdir -p ./backup

    - name: Backup uncompressed files
      run: |
        echo "=== CREANDO BACKUP LOCAL ==="
        cp ./output/01events_past.json ./backup/
        cp ./output/02events_pastINFO.json ./backup/
        echo "Backup de archivos sin comprimir creado en ./backup/"

    - name: Upload backup as artifact
      uses: actions/upload-artifact@v4
      with:
        name: json-backup-uncompressed
        path: |
          ./backup/01events_past.json
          ./backup/02events_pastINFO.json
        retention-days: 7

    - name: Upload compressed files as artifact
      uses: actions/upload-artifact@v4
      with:
        name: json-compressed
        path: |
          ./output/01events_past.json.gz
          ./output/02events_pastINFO.json.gz
        retention-days: 3

    - name: Debug on failure
      if: failure()
      run: |
        echo "=== DEBUGGING FAILURE ==="
        echo "Listando archivos en output:"
        ls -la ./output/ 2>/dev/null || echo "No output directory"
        echo "Listando archivos en backup:"
        ls -la ./backup/ 2>/dev/null || echo "No backup directory"
        echo "=== VERIFICANDO CHROME ==="
        which google-chrome-stable && echo "Chrome encontrado: $(google-chrome-stable --version)" || echo "Chrome NO encontrado"
        which chromedriver && echo "Chromedriver encontrado: $(chromedriver --version)" || echo "Chromedriver NO encontrado"
        echo "=== TAMAÑOS DE ARCHIVOS ==="
        for file in ./output/*.json ./output/*.gz; do
            if [ -f "$file" ]; then
                size=$(stat -c%s "$file")
                echo "$(basename $file): $size bytes"
            fi
        done
