name: 03EventsPastPart

on:
  schedule:
    - cron: '5 2 * * *'
    - cron: '5 4 * * *'
  workflow_dispatch:

concurrency:
  group: eventos-full-scrape
  cancel-in-progress: false

jobs:
  full-scrape:
    runs-on: ubuntu-22.04
    timeout-minutes: 350
    env:
      TZ: Europe/Madrid
      OUT_DIR: ./output
      HEADLESS: "true"
      THROTTLE_PANEL_MS_MIN: "500"
      THROTTLE_PANEL_MS_MAX: "1100"
      THROTTLE_EVENT_S_MIN: "8"
      THROTTLE_EVENT_S_MAX: "14"
      MAX_PANELS_PER_EVENT: "0"
      PER_EVENT_MAX_S: "600"
      MAX_RUNTIME_MIN: "0"
      CHUNK_SIZE: "0"
      CHUNK_OFFSET: "0"
      DEBUG_PARTICIPANTS: "1"
      SNAPSHOT_EVERY: "10"
      STREAM_EXTRA_SLEEP_MIN: "0"
      STREAM_EXTRA_SLEEP_MAX: "0"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install Chrome & ChromeDriver
        shell: bash
        run: |
          set -e
          sudo apt-get update
          sudo apt-get install -y wget gnupg unzip
          wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
          CHROME_VERSION=$(google-chrome-stable --version | grep -oE '[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+')
          URL="https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/${CHROME_VERSION}/linux64/chromedriver-linux64.zip"
          if wget -q --spider "$URL"; then
            wget -O /tmp/chromedriver.zip "$URL"
            unzip -o /tmp/chromedriver.zip -d /tmp/
            sudo mv /tmp/chromedriver-linux64/chromedriver /usr/local/bin/chromedriver
            sudo chmod +x /usr/local/bin/chromedriver
          else
            sudo apt-get install -y chromium-chromedriver
            sudo ln -sf /usr/bin/chromedriver /usr/local/bin/chromedriver
          fi

      - name: Install Python deps
        shell: bash
        run: |
          python -m pip install --upgrade pip
          pip install selenium beautifulsoup4 python-dotenv lxml requests webdriver-manager

      - name: Prepare output dirs
        shell: bash
        run: mkdir -p "${OUT_DIR}" "${OUT_DIR}/participants"

      - name: Ensure uploader is executable
        shell: bash
        run: chmod +x scripts/upload_event.sh

      - name: Export FTP vars
        shell: bash
        env:
          FTP_SERVER:   ${{ secrets.FTP_SERVER }}
          FTP_USERNAME: ${{ secrets.FTP_USERNAME }}
          FTP_PASSWORD: ${{ secrets.FTP_PASSWORD }}
          FTP_REMOTE_DIR_SEC: ${{ secrets.FTP_REMOTE_DIR }}
        run: |
          set -euo pipefail
          CLEAN_DIR="$(printf '%s' "${FTP_REMOTE_DIR_SEC:-/}" | tr -d '\r' | sed 's/^[ \t]\+//; s/[ \t]\+$//' | tr -d '\n')"
          echo "FTP_SCHEME=ftp" >> $GITHUB_ENV
          echo "FTP_HOST=${FTP_SERVER}" >> $GITHUB_ENV
          echo "FTP_USER=${FTP_USERNAME}" >> $GITHUB_ENV
          echo "FTP_PASS=${FTP_PASSWORD}" >> $GITHUB_ENV
          echo "FTP_REMOTE_DIR=${CLEAN_DIR}" >> $GITHUB_ENV
          echo "SLEEP_BETWEEN=2" >> $GITHUB_ENV

      - name: Run Module 1 (events)
        shell: bash
        env:
          FLOW_EMAIL: ${{ secrets.FLOW_EMAIL }}
          FLOW_PASS:  ${{ secrets.FLOW_PASS }}
          HEADLESS: "true"
          MAX_SCROLLS: "15"
          SCROLL_WAIT_S: "3.0"
          LIMIT_EVENTS: "0"
          OUT_DIR: "./output"
        run: |
          python ./flow_events.py --module events
          ls -la ./output || true

      - name: Ensure 01events.json
        shell: bash
        run: |
          if [ ! -f "./output/01events.json" ]; then
            echo "No se gener√≥ ./output/01events.json"
            exit 1
          fi
          ls -la ./output/01events.json

      - name: Run Module 2 (participants, full)
        shell: bash
        env:
          FLOW_EMAIL: ${{ secrets.FLOW_EMAIL }}
          FLOW_PASS:  ${{ secrets.FLOW_PASS }}
        run: |
          python ./flow_participants_debug.py
          ls -la ./output || true
          ls -la ./output/participants || true

      - name: Sanity check JSON
        shell: bash
        run: |
          python - <<'PY'
          import json, pathlib, sys
          p = pathlib.Path("output/02participants.json")
          if not p.exists():
              print("02participants.json no existe"); sys.exit(1)
          data = json.loads(p.read_text(encoding="utf-8"))
          print("Total participantes:", len(data))
          if data:
              sample = {k: data[0].get(k) for k in ("event_id","BinomID","guia","perro","club")}
              print("Ejemplo:", sample)
          PY

      - name: Gzip outputs
        shell: bash
        run: |
          set -e
          for f in output/01events.json output/02participants.json output/02participants_debug.json output/participants/*.json; do
            [ -f "$f" ] && gzip -9 -c "$f" > "${f}.gz" || true
          done
          if [ -f "output/events_stream.jsonl" ]; then
            gzip -9 -c "output/events_stream.jsonl" > "output/events_stream.jsonl.gz"
          fi
          ls -la output/*.gz || true
          ls -la output/participants/*.gz || true

      - name: Upload to FTP
        shell: bash
        run: |
          set -euo pipefail
          for v in FTP_HOST FTP_USER FTP_PASS FTP_REMOTE_DIR; do
            [ -z "${!v:-}" ] && { echo "Falta $v"; exit 1; }
          done
          REMOTE_DIR="${FTP_REMOTE_DIR}/Competiciones/EventsPast/data"
          case "$REMOTE_DIR" in
            /*) : ;;
            *) REMOTE_DIR="/$REMOTE_DIR" ;;
          esac
          REMOTE_DIR="$(printf '%s' "$REMOTE_DIR" | sed 's://*:/:g; s:/*$::')"
          BASE_URL="ftp://${FTP_HOST}${REMOTE_DIR}"
          upload() {
            local SRC="$1" DST="$2"
            [ -f "$SRC" ] || return 0
            for i in 1 2 3; do
              if curl -sS --fail --show-error --ftp-method nocwd --ftp-create-dirs --user "${FTP_USER}:${FTP_PASS}" -T "$SRC" "${BASE_URL}/${DST}"; then
                return 0
              fi
              sleep 3
            done
            return 1
          }
          ok=0
          upload "./output/01events.json.gz" "01events.json.gz" || ok=1
          upload "./output/01events.json"    "01events.json"    || ok=1
          upload "./output/02participants.json.gz"       "02participants.json.gz"       || ok=1
          upload "./output/02participants_debug.json.gz" "02participants_debug.json.gz" || ok=1
          DAY=$(date +%Y%m%d)
          upload "./output/events_stream.jsonl"    "events_stream_${DAY}.jsonl"    || ok=1
          upload "./output/events_stream.jsonl.gz" "events_stream_${DAY}.jsonl.gz" || ok=1
          shopt -s nullglob
          for f in ./output/events_stream_*.jsonl.gz; do
            base=$(basename "$f")
            upload "$f" "$base" || ok=1
          done
          for f in ./output/participants/02p_*.json.gz; do
            base=$(basename "$f")
            upload "$f" "participants/${base}" || ok=1
          done
          exit $ok

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: fullscrape-json-${{ github.run_number }}
          path: |
            output/01events.json
            output/01events.json.gz
            output/02participants.json
            output/02participants.json.gz
            output/02participants_debug.json
            output/02participants_debug.json.gz
            output/events_stream.jsonl
            output/events_stream.jsonl.gz
            output/events_stream_*.jsonl.gz
            output/participants/*.json
            output/participants/*.json.gz
          retention-days: 10
          compression-level: 9
          if-no-files-found: warn
