      - name: Install Python deps
        shell: bash
        run: |
          python -m pip install --upgrade pip
          pip install selenium beautifulsoup4 python-dotenv lxml requests webdriver-manager

      - name: Prepare output dirs
        shell: bash
        run: mkdir -p "${OUT_DIR}" "${OUT_DIR}/participants"

      # ========== Uploader por archivo (usado por flow_events.py) ==========
      - name: Create per-file uploader script (safe)
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p scripts
          cat > scripts/upload_event.sh <<'BASH'
#!/usr/bin/env bash
set -euo pipefail

LOCAL_PATH="${1:-}"
REMOTE_NAME="${2:-}"

# === Config v√≠a entorno ===
FTP_SCHEME="${FTP_SCHEME:-ftp}"               # ftp | ftps | sftp
FTP_HOST="${FTP_HOST:-}"
FTP_USER="${FTP_USER:-}"
FTP_PASS="${FTP_PASS:-}"
FTP_REMOTE_DIR="${FTP_REMOTE_DIR:-/}"
SLEEP_BETWEEN="${SLEEP_BETWEEN:-2}"           # segundos entre subidas

trim_one(){ printf '%s' "$1" | tr -d '\r' | sed 's/^[ \t]\+//; s/[ \t]\+$//' ; }
trim_all_lines(){ tr -d '\r' | sed 's/^[ \t]\+//; s/[ \t]\+$//' | tr -d '\n'; }

FTP_SCHEME="$(trim_one "$FTP_SCHEME")"
FTP_HOST="$(trim_one "$FTP_HOST")"
FTP_USER="$(trim_one "$FTP_USER")"
FTP_PASS="$(trim_one "$FTP_PASS")"
FTP_REMOTE_DIR="$(printf '%s' "$FTP_REMOTE_DIR" | trim_all_lines)"

[[ -z "$LOCAL_PATH" || -z "$REMOTE_NAME" ]] && { echo "Uso: upload_event.sh <local_path> <remote_name>"; exit 2; }
[[ ! -f "$LOCAL_PATH" ]] && { echo "‚ÑπÔ∏è No existe $LOCAL_PATH; se omite."; exit 0; }
for v in FTP_HOST FTP_USER FTP_PASS; do [[ -z "${!v}" ]] && { echo "‚ùå Falta \$${v}"; exit 1; }; done

# Normaliza ruta
[[ "$FTP_REMOTE_DIR" != /* ]] && FTP_REMOTE_DIR="/$FTP_REMOTE_DIR"
FTP_REMOTE_DIR="$(printf '%s' "$FTP_REMOTE_DIR" | sed 's://*:/:g; s:/*$::')"

URL_BASE="${FTP_SCHEME}://${FTP_HOST}${FTP_REMOTE_DIR}"
URL_FILE="${URL_BASE}/${REMOTE_NAME}"

CURL_OPTS=( -sS --fail --show-error --retry 3 --retry-delay 2 --user "$FTP_USER:$FTP_PASS" )
case "$FTP_SCHEME" in
  ftp|ftps) CURL_OPTS+=( --ftp-method nocwd --ftp-create-dirs ) ;;
  sftp)     : ;; # sftp no crea dirs autom√°ticamente
  *) echo "‚ùå Esquema no soportado: $FTP_SCHEME"; exit 1 ;;
esac

echo "‚¨ÜÔ∏è  ${LOCAL_PATH} ‚Üí ${URL_FILE}"
curl "${CURL_OPTS[@]}" -T "$LOCAL_PATH" "$URL_FILE"
echo "‚úÖ Subido: ${REMOTE_NAME}"
sleep "$SLEEP_BETWEEN"
BASH
          chmod +x scripts/upload_event.sh

      # ========== Export & sanitize FTP vars ==========
      - name: Export & sanitize FTP vars for uploader
        shell: bash
        env:
          FTP_SERVER:   ${{ secrets.FTP_SERVER }}
          FTP_USERNAME: ${{ secrets.FTP_USERNAME }}
          FTP_PASSWORD: ${{ secrets.FTP_PASSWORD }}
          FTP_REMOTE_DIR_SEC: ${{ secrets.FTP_REMOTE_DIR }}
        run: |
          set -euo pipefail
          CLEAN_DIR="$(printf '%s' "${FTP_REMOTE_DIR_SEC:-/}" | tr -d '\r' | sed 's/^[ \t]\+//; s/[ \t]\+$//' | tr -d '\n')"
          echo "FTP_SCHEME=ftp" >> $GITHUB_ENV
          echo "FTP_HOST=${{ secrets.FTP_SERVER }}" >> $GITHUB_ENV
          echo "FTP_USER=${{ secrets.FTP_USERNAME }}" >> $GITHUB_ENV
          echo "FTP_PASS=${{ secrets.FTP_PASSWORD }}" >> $GITHUB_ENV
          echo "FTP_REMOTE_DIR=${CLEAN_DIR}" >> $GITHUB_ENV
          echo "SLEEP_BETWEEN=2" >> $GITHUB_ENV

      # ========= M√ìDULO 1: EVENTOS (SIN L√çMITE) =========
      - name: Run Module 1 (events)
        shell: bash
        env:
          FLOW_EMAIL: ${{ secrets.FLOW_EMAIL }}
          FLOW_PASS:  ${{ secrets.FLOW_PASS }}
          HEADLESS: "true"
          MAX_SCROLLS: "15"
          SCROLL_WAIT_S: "3.0"
          LIMIT_EVENTS: "0"
          OUT_DIR: "./output"
        run: |
          echo "=== M√ìDULO 1: EXTRACCI√ìN DE EVENTOS ==="
          python ./flow_events.py --module events
          echo "=== FIN M√ìDULO 1 ==="
          ls -la ./output || true

      - name: Ensure 01events.json
        shell: bash
        run: |
          if [ ! -f "./output/01events.json" ]; then
            echo "‚ùå No se gener√≥ ./output/01events.json"
            exit 1
          fi
          echo "‚úÖ Encontrado 01events.json"
          ls -la ./output/01events.json

      # ========= M√ìDULO 2: PARTICIPANTES (TODOS) =========
      - name: Run Module 2 (participants, full)
        shell: bash
        env:
          FLOW_EMAIL: ${{ secrets.FLOW_EMAIL }}
          FLOW_PASS:  ${{ secrets.FLOW_PASS }}
        run: |
          echo "=== M√ìDULO 2: PARTICIPANTES (FULL) ==="
          python ./flow_participants_debug.py
          echo "=== FIN M√ìDULO 2 ==="
          ls -la ./output || true
          ls -la ./output/participants || true

      - name: Sanity check JSON
        shell: bash
        run: |
          python - <<'PY'
          import json, pathlib, sys
          p = pathlib.Path("output/02participants.json")
          if not p.exists():
              print("‚ùå 02participants.json no existe"); sys.exit(1)
          data = json.loads(p.read_text(encoding="utf-8"))
          print("‚úÖ Total participantes:", len(data))
          if data:
              sample = {k: data[0].get(k) for k in ("event_id","BinomID","guia","perro","club")}
              print("Ejemplo:", sample)
          PY

      - name: Gzip outputs (incluye stream)
        shell: bash
        run: |
          set -e
          for f in output/01events.json output/02participants.json output/02participants_debug.json output/participants/*.json; do
            if [ -f "$f" ]; then
              gzip -9 -c "$f" > "${f}.gz"
            fi
          done
          if [ -f "output/events_stream.jsonl" ]; then
            gzip -9 -c "output/events_stream.jsonl" > "output/events_stream.jsonl.gz"
          fi
          ls -la output/*.gz || true
          ls -la output/participants/*.gz || true

      - name: Upload to FTP (robusto; incluye stream y snapshots)
        shell: bash
        run: |
          set -euo pipefail

          for v in FTP_HOST FTP_USER FTP_PASS FTP_REMOTE_DIR; do
            [ -z "${!v:-}" ] && { echo "‚ùå Falta $v"; exit 1; }
          done

          REMOTE_DIR="${FTP_REMOTE_DIR}/Competiciones/EventsPast/data"
          case "$REMOTE_DIR" in
            /*) : ;;
            *) REMOTE_DIR="/$REMOTE_DIR" ;;
          esac
          REMOTE_DIR="$(printf '%s' "$REMOTE_DIR" | sed 's://*:/:g; s:/*$::')"

          BASE_URL="ftp://${FTP_HOST}${REMOTE_DIR}"
          echo "üì° Subiendo a: ${BASE_URL}/"

          upload() {
            local SRC="$1" DST="$2"
            [ -f "$SRC" ] || { echo "‚ÑπÔ∏è No existe $SRC, se omite."; return 0; }
            for i in 1 2 3; do
              if curl -sS --fail --show-error --ftp-method nocwd --ftp-create-dirs \
                       --user "${FTP_USER}:${FTP_PASS}" \
                       -T "$SRC" "${BASE_URL}/${DST}"; then
                echo "‚úÖ OK: $DST"
                return 0
              fi
              echo "Reintento $i fall√≥ subiendo ${SRC} ‚Üí ${DST}; esperando‚Ä¶"
              sleep 3
            done
            echo "‚ùå Fallo subiendo ${SRC} ‚Üí ${DST}"; return 1
          }

          ok=0
          upload "./output/01events.json.gz" "01events.json.gz" || ok=1
          upload "./output/01events.json"    "01events.json"    || ok=1
          upload "./output/02participants.json.gz"       "02participants.json.gz"       || ok=1
          upload "./output/02participants_debug.json.gz" "02participants_debug.json.gz" || ok=1

          DAY=$(date +%Y%m%d)
          upload "./output/events_stream.jsonl"    "events_stream_${DAY}.jsonl"    || ok=1
          upload "./output/events_stream.jsonl.gz" "events_stream_${DAY}.jsonl.gz" || ok=1

          shopt -s nullglob
          for f in ./output/events_stream_*.jsonl.gz; do
            base=$(basename "$f")
            upload "$f" "$base" || ok=1
          done

          for f in ./output/participants/02p_*.json.gz; do
            base=$(basename "$f")
            upload "$f" "participants/${base}" || ok=1
          done

          exit $ok

      - name: Upload artifacts (backup)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: fullscrape-json-${{ github.run_number }}
          path: |
            output/01events.json
            output/01events.json.gz
            output/02participants.json
            output/02participants.json.gz
            output/02participants_debug.json
            output/02participants_debug.json.gz
            output/events_stream.jsonl
            output/events_stream.jsonl.gz
            output/events_stream_*.jsonl.gz
            output/participants/*.json
            output/participants/*.json.gz
          retention-days: 10
          compression-level: 9
          if-no-files-found: warn
